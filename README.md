# ðŸ¦« Beaver & Watershed Health Pipeline

An end-to-end data engineering pipeline that ingests North American beaver occurrence data and USGS dissolved oxygen readings, spatially joins them, and surfaces insights via a deployed Streamlit dashboard.

**Live Dashboard:** [Add Streamlit URL here once deployed]

## The Question
Do areas with beaver activity correlate with healthy dissolved oxygen levels in nearby California waterways?

## Architecture
```
GBIF API (beaver sightings)  â”€â”€â”
                               â”œâ”€â”€â–º S3 Raw Bucket â”€â”€â–º Lambda (spatial join) â”€â”€â–º S3 Processed â”€â”€â–º RDS PostgreSQL â”€â”€â–º Streamlit Dashboard
USGS API (dissolved oxygen)  â”€â”€â”˜
```

## Tech Stack
- **Cloud:** AWS S3, AWS Lambda, AWS RDS (PostgreSQL)
- **Pipeline:** Python, pandas, numpy, scikit-learn (BallTree)
- **Dashboard:** Streamlit (deployed on Streamlit Cloud)
- **Data Sources:** GBIF Occurrence API, USGS Water Services API

## Key Results
- 5,100+ US beaver occurrence records processed (43,000 in production)
- 41 California USGS stream monitoring stations matched
- 260 California beaver sightings spatially joined to nearest water station
- Average distance to nearest station: 49.3 km
- Dissolved oxygen range: 7.3 - 10.7 mg/L (all healthy, >6.0 threshold)
- Sacramento River watershed shows highest beaver density (80 sightings)

## Project Structure
```
beaver-watershed-pipeline/
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ beaver_data_engineer.ipynb   # Colab prototype notebook
â”œâ”€â”€ data/
â”‚   â””â”€â”€ beaver_water_joined.csv      # Final joined dataset (260 rows)
â”œâ”€â”€ lambda/
â”‚   â”œâ”€â”€ handler.py                   # Lambda function (full pipeline)
â”‚   â””â”€â”€ requirements.txt             # Lambda dependencies
â”œâ”€â”€ streamlit/
â”‚   â””â”€â”€ app.py                       # Streamlit dashboard
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ create_tables.sql            # RDS table definitions
â””â”€â”€ infrastructure/
    â””â”€â”€ setup_notes.md               # AWS setup instructions
```

## Running Locally
```bash
pip install -r requirements.txt

# Run Streamlit dashboard (uses local CSV if no RDS connection)
streamlit run streamlit/app.py
```

## Data Sources
- [GBIF](https://www.gbif.org/) - Global Biodiversity Information Facility
- [USGS Water Services](https://waterservices.usgs.gov/) - National Water Information System
